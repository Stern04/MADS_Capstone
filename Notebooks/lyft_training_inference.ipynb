{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this Notebook, we assume either lyft_preprocessing.ipynb has been run to produced the processed images or you have directly downloaded the processed images. The whole notebook outline is provided below. I decided to leave all function defenitions defined in this Notebook rather than keeping them in a utils.py file and importing them. I may change this in the future, but I wanted to make access as easy and transparent as possible at the expense of increasing the Notebook length.\n",
    "# The main steps this Notebook walks you through are: \n",
    "* Importing a plug and play Pytorch Resnet50 model for binary Image Classification where the positive category is Pedestrian\n",
    "* Training a model on CPU or GPU if available\n",
    "* Load the various trained models and apply them to a Validation set to experiment with model Inference\n",
    "* Analyze results\n",
    "* Get a start on Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imports and inital data read.\n",
    "- With our Data Processing finished, we now shift to create and train our models.\n",
    "- Define our custom Dataset classes for image classification and object detection.\n",
    "- Read in our data with an instance of our Lyft_image_classification_CustomDataset class.\n",
    "    - Each Dataset instance will instantiated with the model it will be given to in mind. For example, our ResNet model is designed for image classification where the full object is centered in the image.\n",
    "      - Remind ourselves what dataloader actually is. It is a grouping of binary labels indicating target category and the corresponding images as tensors.\n",
    "      - Print out the first 5 batches and observe the amount of positive and negative labels. With 9 categories, it is not surprising that the positive labels are outnumbered. Still, our basic Resnet50 model below does well.\n",
    "- Image Classificaiton\n",
    "  - Import a ResNet50 model and train it on our images with the category object centered.\n",
    "    - First, check if GPU is available and move the model to GPU if it is\n",
    "  - Train\n",
    "  - Train Results\n",
    "    - Load all of the trained models back in and stich their results together into a summary df.\n",
    "      - WARNING: The cell below will overwrite \"all_model_results.csv\" if you have alreayd created it.\n",
    "- Validation/Inference\n",
    "  - Visualize the performance metrics either for training or validation\n",
    "    - F1 Score heatmap\n",
    "    - Visualize the output of the first layer which is a convolution layer with kernel 7x7. This is just to remind us what we are dealing with.\n",
    "    - Validation/Inference Results\n",
    "- Object Detection\n",
    "    - Heatmap. Note: We use both training and validation data to aggregate a heat map. The heat map itelf isn't involved as a parameter in the model. This is simply just using a greater sample size to determine the places within the full sized images that are most and least likely for pedestrians to occur. This way, we can decrease the image space that our model will scan for each image.\n",
    "  - Import FasterRCNN model.\n",
    "  - Create our Dataset and Dataloader objects for object detection\n",
    "  - Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and inital data read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "#Data visualization libraries\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torchvision import models\n",
    "from torchvision.models.resnet import ResNet50_Weights\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_Weights\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load the SDK\n",
    "from lyft_dataset_sdk.lyftdataset import LyftDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the option to display all rows\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set user_path_prefix variable. This variable must be set in order to make all filepaths relative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_path_prefix = r\"S:\\MADS\\Capstone\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With our Data Processing finished, we now shift to create and train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 category,\n",
      "18 attribute,\n",
      "4 visibility,\n",
      "18421 instance,\n",
      "10 sensor,\n",
      "148 calibrated_sensor,\n",
      "177789 ego_pose,\n",
      "180 log,\n",
      "180 scene,\n",
      "22680 sample,\n",
      "189504 sample_data,\n",
      "638179 sample_annotation,\n",
      "1 map,\n",
      "Done loading in 8.4 seconds.\n",
      "======\n",
      "Reverse indexing ...\n",
      "Done reverse indexing in 2.6 seconds.\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\")\n",
    "json_path = os.path.join(user_path_prefix, \"3d-object-detection-for-autonomous-vehicles\\Train\\data\")\n",
    "lyftdata = LyftDataset(data_path=data_path, json_path=json_path, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our custom Dataset classes for image classification and object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lyft_image_classification_CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for image classification, specifically designed to handle\n",
    "    cropped images for a binary classification task.\n",
    "\n",
    "    This class is a subclass of `torch.utils.data.Dataset` and is meant to be used\n",
    "    with PyTorch's DataLoader to facilitate batch processing and data shuffling.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    cropped_images_dir (str): The directory path where cropped images are stored.\n",
    "    target_category_name (str): The name of the target category for classification.\n",
    "    required_size (int, optional): The size to which images should be sized. Default is 224.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    The dataset assumes that images are stored in subdirectories within `cropped_images_dir`,\n",
    "    where each subdirectory name begins with the category name of the images it contains.\n",
    "    The class uses this naming convention to assign labels to images.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cropped_images_dir, target_category_name, required_size=224):\n",
    "        self.cropped_images_dir = cropped_images_dir\n",
    "        self.required_size = required_size\n",
    "        self.image_filenames = os.listdir(cropped_images_dir)\n",
    "        self.data = []\n",
    "        for category_folder in os.listdir(cropped_images_dir):\n",
    "            category_dir = os.path.join(cropped_images_dir, category_folder)\n",
    "            if os.path.isdir(category_dir):  # Check if it's a directory\n",
    "                category_name = category_folder.split(\"_\")[0]\n",
    "                is_target_category = category_name == target_category_name\n",
    "                label = 1 if is_target_category else 0\n",
    "\n",
    "                for filename in os.listdir(category_dir):\n",
    "                    file_path = os.path.join(category_dir, filename)\n",
    "                    if os.path.isfile(file_path):  # Check if it's a file\n",
    "                        self.data.append((file_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image_name = re.search(r'([^\\\\]+)(?=\\.\\w+$)', img_path).group(1)\n",
    "\n",
    "        # Convert the image to tensor and normalize\n",
    "        image = transforms.ToTensor()(image)\n",
    "        image = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(image)\n",
    "\n",
    "        return image, label, image_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for default transformations. It is convention to not define transforms within the Dataset class.\n",
    "def default_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "class Lyft_binary_object_detection_CustomDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for binary object detection tasks.\n",
    "\n",
    "    This class works with PyTorch's DataLoader to efficiently handle data during model training. It is tailored for a data format where each image is associated with bounding box coordinates and binary labels, \n",
    "    along with placeholders for predicted data.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_box_lookup (dict): A dictionary containing image file paths and corresponding bounding box, label, and placeholder data for predictions. Labels should be binary (1 or 0).\n",
    "    images_base_path (str): Base directory path where image files are stored.\n",
    "    transform (callable, optional): A transform to be applied on each image. If None, default_transform is used.\n",
    "    random_sample (float, optional): A fraction (between 0 and 1) of the dataset to randomly sample. If None, the entire dataset is used.\n",
    "    positive_imgs_only (bool, optional): If True, only includes images with at least one instance of the positive class (label==1).\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The transform function is expected to handle the conversion of images to tensors and their normalization.\n",
    "    - 'image_box_lookup' format: Keys are image filenames and values are dictionaries with 'boxes' (list of coordinates), \n",
    "      'labels' (list of int, 0 or 1), and placeholders for 'predicted_boxes' and 'predicted_labels' (initially empty lists).\n",
    "    - If 'positive_imgs_only' is True, the dataset is filtered to include only images with at least one positive instance. This can reduce total training time.\n",
    "    - If 'random_sample' is provided, the dataset is subsampled to the specified fraction. This can reduce total training time, and is good for experimentation.\n",
    "    - This class assumes binary classification within object detection, with labels 0 or 1.\n",
    "\n",
    "    Example of 'image_box_lookup' structure:\n",
    "    {\n",
    "        \"image1.jpg\": {\n",
    "            \"boxes\": [[x1, y1, x2, y2], ...], \n",
    "            \"labels\": [1, 0, ...],\n",
    "            \"predicted_boxes\": [],\n",
    "            \"predicted_labels\": []\n",
    "        },\n",
    "        \"image2.jpg\": {\n",
    "            \"boxes\": [[x1, y1, x2, y2], ...], \n",
    "            \"labels\": [0, 1, ...],\n",
    "            \"predicted_boxes\": [],\n",
    "            \"predicted_labels\": []\n",
    "        },\n",
    "        ...\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_box_lookup, images_base_path, transform=None, random_sample = None, positive_imgs_only = False):\n",
    "        self.images_base_path = images_base_path\n",
    "        self.transform = transform if transform else default_transform()\n",
    "        self.image_box_lookup = image_box_lookup\n",
    "        if positive_imgs_only:\n",
    "            positive_images = []\n",
    "            for k, v in self.image_box_lookup.items():\n",
    "                labels = v[\"labels\"]\n",
    "                if any(labels):\n",
    "                    positive_images.append(k)\n",
    "            self.image_box_lookup = {k: self.image_box_lookup[k] for k in positive_images}\n",
    "\n",
    "        if random_sample:\n",
    "            # Ensure random_sample is a valid fraction\n",
    "            if not (0 < random_sample <= 1):\n",
    "                raise ValueError(\"random_sample must be a decimal between 0 and 1.\")\n",
    "\n",
    "            # Randomly sample the specified fraction of data\n",
    "            total_items = len(self.image_box_lookup)\n",
    "            sample_size = int(total_items * random_sample)\n",
    "            sampled_items = random.sample(list(self.image_box_lookup.items()), sample_size)\n",
    "            self.image_box_lookup = dict(sampled_items)\n",
    "\n",
    "        self.file_names = self.image_box_lookup.keys()\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_box_lookup)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = list(self.image_box_lookup.keys())[idx]\n",
    "        image_path = os.path.join(self.images_base_path, image_name)\n",
    "        image = Image.open(image_path).convert(\"RGB\")  # Convert image to RGB just in case.\n",
    "        # Convert the image to tensor and normalize (if transform is given)\n",
    "        image = self.transform(image)\n",
    "\n",
    "\n",
    "        # Retrieve boxes and labels for the image\n",
    "        boxes = torch.as_tensor(self.image_box_lookup[image_name]['boxes'], dtype=torch.float32)\n",
    "        labels = torch.as_tensor(self.image_box_lookup[image_name]['labels'], dtype=torch.int64)\n",
    "\n",
    "        # Ensure labels tensor is always 1D\n",
    "        if len(labels.shape) == 0:\n",
    "            labels = labels.unsqueeze(0)\n",
    "\n",
    "\n",
    "        # Create a dictionary for the targets\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in our data with an instance of our Lyft_image_classification_CustomDataset class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each Dataset instance will be instantiated with the model it will be given to in mind. For example, our ResNet50 model is designed for image classification where the full object is centered in the image.This is why we load in the cropped images and not the full images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of batches to anticipate:  756.53125\n"
     ]
    }
   ],
   "source": [
    "cropped_images_dir = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\images\\Image_Classification\\train_cropped_images\\224\")\n",
    "dataset = Lyft_image_classification_CustomDataset(cropped_images_dir, target_category_name = \"pedestrian\", required_size=224)\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "print(\"total number of batches to anticipate: \", len(dataset)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remind ourselves what dataloader actually is. It is a grouping of binary labels indicating target category and the corresponding images as tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in dataloader:\n",
    "#     data_batch_tensor = data[0]\n",
    "#     data_batch_label = data[1]\n",
    "#     break\n",
    "\n",
    "# print(len(data_batch_tensor), len(data_batch_label))\n",
    "# print(data_batch_label[0])\n",
    "# print(data_batch_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print out the first 5 batches and observe the amount of positive and negative labels. With 9 categories, it is not surprising that the positive labels are outnumbered. Still, our basic Resnet50 model does well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_labels = []\n",
    "for i, data in enumerate(dataloader):\n",
    "    # print(f\"Batch {i}: Labels - {data[1]}\")\n",
    "    sample_labels.append(data[1])\n",
    "    if i == 5:  # Check first 5 batches\n",
    "        break\n",
    "\n",
    "positives = [torch.sum(tensor == 1).item() for tensor in sample_labels]\n",
    "negatives = [torch.sum(tensor == 0).item() for tensor in sample_labels]\n",
    "\n",
    "n_tensors = len(sample_labels)\n",
    "index = np.arange(n_tensors)\n",
    "bar_width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bar1 = ax.bar(index, negatives, bar_width, label='0 (Negative)')\n",
    "bar2 = ax.bar(index + bar_width, positives, bar_width, label='1 (Positive)')\n",
    "\n",
    "ax.set_xlabel('Tensor Index')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Frequency of Positive and Negative Labels per Tensor')\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels([f'Tensor {i+1}' for i in range(n_tensors)])\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classificaiton "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import a ResNet50 model and train it on our images with the category object centered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, check if GPU is available and move the model to GPU if it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_res50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model_res50.fc.in_features\n",
    "print(num_ftrs)\n",
    "model_res50.fc = nn.Linear(num_ftrs, 2) # Modify the last layer for binary classification\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_res50 = model_res50.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet50_classification(model_instance, num_epochs, batch_size, input_images_path, out_results_path, required_imgage_size=224, target_category_name=\"pedestrian\",\n",
    "                                  criterion=nn.CrossEntropyLoss(), learning_rate = 0.001, save_per_epoch=False):\n",
    "    \"\"\"\n",
    "    Trains a ResNet50 model for image classification tasks with specified parameters.\n",
    "\n",
    "    This function handles the training process including data loading, batch processing, loss computation, and optimization. It supports saving the model state and key metrics at the end of each epoch or after all epochs.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_instance: The ResNet50 model instance to be trained.\n",
    "    num_epochs (int): The number of epochs to train the model.\n",
    "    batch_size (int): The batch size used for training.\n",
    "    input_images_path (str): Path to the directory containing training images.\n",
    "    out_results_path (str): Path where the trained model and metrics will be saved.\n",
    "    required_imgage_size (int, optional): Size that input images are expected to be in. Default is 224.\n",
    "    target_category_name (str, optional): The target category for classification. Default is \"pedestrian\".\n",
    "    criterion: Loss function used for training. Default is `nn.CrossEntropyLoss()`.\n",
    "    learning_rate (float, optional): Learning rate for the optimizer. Default is 0.001.\n",
    "    save_per_epoch (bool, optional): If True, saves the model and metrics after each epoch. Otherwise, saves once after all epochs. Default is False.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The optimizer used is Adam, and currently, there is no flexibility for choosing a different optimizer. This may be updated in future releases.\n",
    "    - The function computes and prints loss, accuracy, precision, recall, and F1 score for each epoch if save_per_epoch == True. If it is False, it only computes values for final epoch.\n",
    "    - The model and metrics are saved as a checkpoint in '.pth' format, which uses Python's pickle module for serialization.\n",
    "    - It is assumed that the input images are organized in a way that is compatible with the `Lyft_image_classification_CustomDataset` class.\n",
    "    \"\"\"\n",
    "\n",
    "    optimizer = Adam(model_instance.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #Set training mode at beginning of each epoch in case we train on validation data within epoch with requires model.eval()\n",
    "        model_instance.train()\n",
    "\n",
    "        #Creat instances of our custom Dataset and subsequent default Dataloader\n",
    "        dataset = Lyft_image_classification_CustomDataset(input_images_path, target_category_name, required_imgage_size)\n",
    "        batch_size = batch_size\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        print(f\"total number of batches to anticipate for epoch {epoch}: \", len(dataset)/batch_size)\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        running_true_positives = 0\n",
    "        running_false_positives = 0\n",
    "        running_false_negatives = 0\n",
    "\n",
    "        # Iterate over data by batch\n",
    "        # We only need inputs and labels for training. The third placeholder is for filepaths to go back and address the images that created incorrect predictions during validation/inference. We dont need it in training.\n",
    "        for inputs, labels, _ in dataloader:\n",
    "            #Make sure input data and labels are on the GPU device.\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_res50(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Statistics\n",
    "            # Assuming that loss.item() is the average loss of the predictions in the batch. Multiply by batch size to get the total loss (mean(loss)*batch_size).\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            # Calculate True Positives, False Positives, False Negatives\n",
    "            for i in range(len(labels)):\n",
    "                if preds[i] == labels[i] == 1:  # True Positive\n",
    "                    running_true_positives += 1\n",
    "                elif preds[i] == 1 and labels[i] == 0:  # False Positive\n",
    "                    running_false_positives += 1\n",
    "                elif preds[i] == 0 and labels[i] == 1:  # False Negative\n",
    "                    running_false_negatives += 1\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataset)\n",
    "        # Calculate Precision, Recall, and F1 Score after the loop\n",
    "        precision = running_true_positives / (running_true_positives + running_false_positives) if (running_true_positives + running_false_positives) > 0 else 0\n",
    "        recall = running_true_positives / (running_true_positives + running_false_negatives) if (running_true_positives + running_false_negatives) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1} Loss: {epoch_loss:.4f} Precision: {precision:.4f} Recall: {recall:.4f} F1 Score: {f1_score:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        if save_per_epoch:\n",
    "            # We save out the model within each epoch. This is to retain completed work if the training loop fails at some point during execution.\n",
    "            # Note: We refer to our metrics as \"final\" in case we don't finish all epochs, but they can be interpreted as \"running\" until the last epoch is complete.\n",
    "            # Save the model state and metrics in a dictionary\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model_instance.state_dict(),\n",
    "                'final_loss': epoch_loss,\n",
    "                'final_accuracy': epoch_acc,\n",
    "                'final_precision': precision,\n",
    "                'final_recall': recall,\n",
    "                'final_F1': f1_score\n",
    "            }\n",
    "\n",
    "            # Save the checkpoint\n",
    "            # It is Pytorch convention to save checkpoints of model states as '.pth' which is short of 'Pytorch'. This uses Python pickle module to serialize the data.\n",
    "            model_checkpoint_name = f'model_res50_epoch_{epoch}_batchsize_{batch_size}_lr_{learning_rate}.pth'\n",
    "            model_outpath = os.path.join(out_results_path, model_checkpoint_name)\n",
    "            torch.save(checkpoint, model_outpath)\n",
    "    \n",
    "    if not save_per_epoch :\n",
    "        # All epochs have been completed. Save the model state and metrics in a dictionary\n",
    "        checkpoint = {\n",
    "            'model_state_dict': model_instance.state_dict(),\n",
    "            'final_loss': epoch_loss,\n",
    "            'final_accuracy': epoch_acc,\n",
    "            'final_precision': precision,\n",
    "            'final_recall': recall,\n",
    "            'final_F1': f1_score\n",
    "        }\n",
    "\n",
    "        # Save the checkpoint\n",
    "        # It is Pytorch convention to save checkpoints of model states as '.pth' which is short of 'Pytorch'. This uses Python pickle module to serialize the data.\n",
    "        model_checkpoint_name = f'model_res50_batchsize_{batch_size}_lr_{learning_rate}.pth'\n",
    "        model_outpath = os.path.join(out_results_path, model_checkpoint_name)\n",
    "        torch.save(checkpoint, model_outpath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train 9 Resnet50 models each with a different combination of 3 batch sizes and 3 learning rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: If you do not want to perform training and want to skip to the trained models that come with the repository, you may skip down to \"Train Results\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of batches to anticipate for epoch 0:  484.18\n",
      "Epoch 0/9 Loss: 0.1270 Precision: 0.8549 Recall: 0.8534 F1 Score: 0.8541 Acc: 0.9508\n",
      "total number of batches to anticipate for epoch 1:  484.18\n",
      "Epoch 1/9 Loss: 0.0930 Precision: 0.8954 Recall: 0.9004 F1 Score: 0.8979 Acc: 0.9654\n",
      "total number of batches to anticipate for epoch 2:  484.18\n",
      "Epoch 2/9 Loss: 0.0743 Precision: 0.9179 Recall: 0.9190 F1 Score: 0.9184 Acc: 0.9724\n",
      "total number of batches to anticipate for epoch 3:  484.18\n",
      "Epoch 3/9 Loss: 0.0609 Precision: 0.9304 Recall: 0.9418 F1 Score: 0.9360 Acc: 0.9783\n",
      "total number of batches to anticipate for epoch 4:  484.18\n",
      "Epoch 4/9 Loss: 0.0545 Precision: 0.9367 Recall: 0.9484 F1 Score: 0.9425 Acc: 0.9805\n",
      "total number of batches to anticipate for epoch 5:  484.18\n",
      "Epoch 5/9 Loss: 0.0488 Precision: 0.9435 Recall: 0.9518 F1 Score: 0.9476 Acc: 0.9822\n",
      "total number of batches to anticipate for epoch 6:  484.18\n",
      "Epoch 6/9 Loss: 0.0427 Precision: 0.9489 Recall: 0.9584 F1 Score: 0.9536 Acc: 0.9843\n",
      "total number of batches to anticipate for epoch 7:  484.18\n",
      "Epoch 7/9 Loss: 0.0420 Precision: 0.9497 Recall: 0.9567 F1 Score: 0.9532 Acc: 0.9841\n",
      "total number of batches to anticipate for epoch 8:  484.18\n",
      "Epoch 8/9 Loss: 0.0321 Precision: 0.9626 Recall: 0.9699 F1 Score: 0.9662 Acc: 0.9886\n",
      "total number of batches to anticipate for epoch 9:  484.18\n",
      "Epoch 9/9 Loss: 0.0293 Precision: 0.9648 Recall: 0.9716 F1 Score: 0.9682 Acc: 0.9892\n",
      "total number of batches to anticipate for epoch 0:  484.18\n",
      "Epoch 0/9 Loss: 0.1873 Precision: 0.7980 Recall: 0.7785 F1 Score: 0.7882 Acc: 0.9294\n",
      "total number of batches to anticipate for epoch 1:  484.18\n",
      "Epoch 1/9 Loss: 0.1335 Precision: 0.8407 Recall: 0.8566 F1 Score: 0.8486 Acc: 0.9484\n",
      "total number of batches to anticipate for epoch 2:  484.18\n",
      "Epoch 2/9 Loss: 0.1159 Precision: 0.8613 Recall: 0.8796 F1 Score: 0.8703 Acc: 0.9558\n",
      "total number of batches to anticipate for epoch 3:  484.18\n",
      "Epoch 3/9 Loss: 0.1005 Precision: 0.8779 Recall: 0.9011 F1 Score: 0.8894 Acc: 0.9622\n",
      "total number of batches to anticipate for epoch 4:  484.18\n",
      "Epoch 4/9 Loss: 0.0992 Precision: 0.8731 Recall: 0.8994 F1 Score: 0.8861 Acc: 0.9610\n",
      "total number of batches to anticipate for epoch 5:  484.18\n",
      "Epoch 5/9 Loss: 0.0875 Precision: 0.8911 Recall: 0.9153 F1 Score: 0.9031 Acc: 0.9668\n",
      "total number of batches to anticipate for epoch 6:  484.18\n",
      "Epoch 6/9 Loss: 0.0880 Precision: 0.8953 Recall: 0.9168 F1 Score: 0.9059 Acc: 0.9679\n",
      "total number of batches to anticipate for epoch 7:  484.18\n",
      "Epoch 7/9 Loss: 0.0773 Precision: 0.9016 Recall: 0.9266 F1 Score: 0.9139 Acc: 0.9705\n",
      "total number of batches to anticipate for epoch 8:  484.18\n",
      "Epoch 8/9 Loss: 0.0738 Precision: 0.9102 Recall: 0.9283 F1 Score: 0.9192 Acc: 0.9724\n",
      "total number of batches to anticipate for epoch 9:  484.18\n",
      "Epoch 9/9 Loss: 0.0690 Precision: 0.9156 Recall: 0.9351 F1 Score: 0.9253 Acc: 0.9745\n",
      "total number of batches to anticipate for epoch 0:  484.18\n",
      "Epoch 0/9 Loss: 0.0523 Precision: 0.9188 Recall: 0.9665 F1 Score: 0.9420 Acc: 0.9799\n",
      "total number of batches to anticipate for epoch 1:  484.18\n",
      "Epoch 1/9 Loss: 0.0441 Precision: 0.9423 Recall: 0.9594 F1 Score: 0.9508 Acc: 0.9832\n",
      "total number of batches to anticipate for epoch 2:  484.18\n",
      "Epoch 2/9 Loss: 0.0431 Precision: 0.9457 Recall: 0.9630 F1 Score: 0.9543 Acc: 0.9844\n",
      "total number of batches to anticipate for epoch 3:  484.18\n",
      "Epoch 3/9 Loss: 0.0420 Precision: 0.9457 Recall: 0.9633 F1 Score: 0.9544 Acc: 0.9845\n",
      "total number of batches to anticipate for epoch 4:  484.18\n",
      "Epoch 4/9 Loss: 0.0407 Precision: 0.9498 Recall: 0.9640 F1 Score: 0.9569 Acc: 0.9853\n",
      "total number of batches to anticipate for epoch 5:  484.18\n",
      "Epoch 5/9 Loss: 0.0400 Precision: 0.9526 Recall: 0.9643 F1 Score: 0.9584 Acc: 0.9859\n",
      "total number of batches to anticipate for epoch 6:  484.18\n",
      "Epoch 6/9 Loss: 0.0381 Precision: 0.9518 Recall: 0.9667 F1 Score: 0.9592 Acc: 0.9861\n",
      "total number of batches to anticipate for epoch 7:  484.18\n",
      "Epoch 7/9 Loss: 0.0368 Precision: 0.9542 Recall: 0.9635 F1 Score: 0.9588 Acc: 0.9860\n",
      "total number of batches to anticipate for epoch 8:  484.18\n",
      "Epoch 8/9 Loss: 0.0360 Precision: 0.9563 Recall: 0.9684 F1 Score: 0.9623 Acc: 0.9872\n",
      "total number of batches to anticipate for epoch 9:  484.18\n",
      "Epoch 9/9 Loss: 0.0359 Precision: 0.9532 Recall: 0.9679 F1 Score: 0.9605 Acc: 0.9866\n",
      "total number of batches to anticipate for epoch 0:  756.53125\n",
      "Epoch 0/9 Loss: 0.0412 Precision: 0.9508 Recall: 0.9611 F1 Score: 0.9559 Acc: 0.9850\n",
      "total number of batches to anticipate for epoch 1:  756.53125\n",
      "Epoch 1/9 Loss: 0.0348 Precision: 0.9562 Recall: 0.9682 F1 Score: 0.9622 Acc: 0.9872\n",
      "total number of batches to anticipate for epoch 2:  756.53125\n",
      "Epoch 2/9 Loss: 0.0309 Precision: 0.9618 Recall: 0.9723 F1 Score: 0.9670 Acc: 0.9888\n",
      "total number of batches to anticipate for epoch 3:  756.53125\n",
      "Epoch 3/9 Loss: 0.0269 Precision: 0.9663 Recall: 0.9755 F1 Score: 0.9709 Acc: 0.9901\n",
      "total number of batches to anticipate for epoch 4:  756.53125\n",
      "Epoch 4/9 Loss: 0.0247 Precision: 0.9695 Recall: 0.9787 F1 Score: 0.9741 Acc: 0.9912\n",
      "total number of batches to anticipate for epoch 5:  756.53125\n",
      "Epoch 5/9 Loss: 0.0209 Precision: 0.9754 Recall: 0.9809 F1 Score: 0.9782 Acc: 0.9926\n",
      "total number of batches to anticipate for epoch 6:  756.53125\n",
      "Epoch 6/9 Loss: 0.0183 Precision: 0.9786 Recall: 0.9826 F1 Score: 0.9806 Acc: 0.9934\n",
      "total number of batches to anticipate for epoch 7:  756.53125\n",
      "Epoch 7/9 Loss: 0.0180 Precision: 0.9790 Recall: 0.9834 F1 Score: 0.9812 Acc: 0.9936\n",
      "total number of batches to anticipate for epoch 8:  756.53125\n",
      "Epoch 8/9 Loss: 0.0157 Precision: 0.9820 Recall: 0.9853 F1 Score: 0.9836 Acc: 0.9945\n",
      "total number of batches to anticipate for epoch 9:  756.53125\n",
      "Epoch 9/9 Loss: 0.0122 Precision: 0.9868 Recall: 0.9860 F1 Score: 0.9864 Acc: 0.9954\n",
      "total number of batches to anticipate for epoch 0:  756.53125\n",
      "Epoch 0/9 Loss: 0.0740 Precision: 0.9154 Recall: 0.9298 F1 Score: 0.9225 Acc: 0.9736\n",
      "total number of batches to anticipate for epoch 1:  756.53125\n",
      "Epoch 1/9 Loss: 0.0644 Precision: 0.9219 Recall: 0.9354 F1 Score: 0.9286 Acc: 0.9757\n",
      "total number of batches to anticipate for epoch 2:  756.53125\n",
      "Epoch 2/9 Loss: 0.0590 Precision: 0.9278 Recall: 0.9432 F1 Score: 0.9354 Acc: 0.9780\n",
      "total number of batches to anticipate for epoch 3:  756.53125\n",
      "Epoch 3/9 Loss: 0.0579 Precision: 0.9286 Recall: 0.9425 F1 Score: 0.9355 Acc: 0.9781\n",
      "total number of batches to anticipate for epoch 4:  756.53125\n",
      "Epoch 4/9 Loss: 0.0544 Precision: 0.9326 Recall: 0.9486 F1 Score: 0.9405 Acc: 0.9798\n",
      "total number of batches to anticipate for epoch 5:  756.53125\n",
      "Epoch 5/9 Loss: 0.0538 Precision: 0.9359 Recall: 0.9462 F1 Score: 0.9410 Acc: 0.9800\n",
      "total number of batches to anticipate for epoch 6:  756.53125\n",
      "Epoch 6/9 Loss: 0.0497 Precision: 0.9407 Recall: 0.9506 F1 Score: 0.9456 Acc: 0.9815\n",
      "total number of batches to anticipate for epoch 7:  756.53125\n",
      "Epoch 7/9 Loss: 0.0448 Precision: 0.9446 Recall: 0.9557 F1 Score: 0.9501 Acc: 0.9831\n",
      "total number of batches to anticipate for epoch 8:  756.53125\n",
      "Epoch 8/9 Loss: 0.0410 Precision: 0.9497 Recall: 0.9604 F1 Score: 0.9550 Acc: 0.9847\n",
      "total number of batches to anticipate for epoch 9:  756.53125\n",
      "Epoch 9/9 Loss: 0.0435 Precision: 0.9478 Recall: 0.9604 F1 Score: 0.9540 Acc: 0.9844\n",
      "total number of batches to anticipate for epoch 0:  756.53125\n",
      "Epoch 0/9 Loss: 0.0307 Precision: 0.9663 Recall: 0.9672 F1 Score: 0.9667 Acc: 0.9888\n",
      "total number of batches to anticipate for epoch 1:  756.53125\n",
      "Epoch 1/9 Loss: 0.0268 Precision: 0.9659 Recall: 0.9770 F1 Score: 0.9714 Acc: 0.9903\n",
      "total number of batches to anticipate for epoch 2:  756.53125\n",
      "Epoch 2/9 Loss: 0.0237 Precision: 0.9727 Recall: 0.9785 F1 Score: 0.9756 Acc: 0.9917\n",
      "total number of batches to anticipate for epoch 3:  756.53125\n",
      "Epoch 3/9 Loss: 0.0229 Precision: 0.9733 Recall: 0.9804 F1 Score: 0.9768 Acc: 0.9922\n",
      "total number of batches to anticipate for epoch 4:  756.53125\n",
      "Epoch 4/9 Loss: 0.0208 Precision: 0.9776 Recall: 0.9829 F1 Score: 0.9802 Acc: 0.9933\n",
      "total number of batches to anticipate for epoch 5:  756.53125\n",
      "Epoch 5/9 Loss: 0.0199 Precision: 0.9769 Recall: 0.9826 F1 Score: 0.9797 Acc: 0.9931\n",
      "total number of batches to anticipate for epoch 6:  756.53125\n",
      "Epoch 6/9 Loss: 0.0185 Precision: 0.9783 Recall: 0.9831 F1 Score: 0.9807 Acc: 0.9935\n",
      "total number of batches to anticipate for epoch 7:  756.53125\n",
      "Epoch 7/9 Loss: 0.0176 Precision: 0.9812 Recall: 0.9848 F1 Score: 0.9830 Acc: 0.9943\n",
      "total number of batches to anticipate for epoch 8:  756.53125\n",
      "Epoch 8/9 Loss: 0.0172 Precision: 0.9815 Recall: 0.9868 F1 Score: 0.9841 Acc: 0.9946\n",
      "total number of batches to anticipate for epoch 9:  756.53125\n",
      "Epoch 9/9 Loss: 0.0169 Precision: 0.9810 Recall: 0.9848 F1 Score: 0.9829 Acc: 0.9942\n",
      "total number of batches to anticipate for epoch 0:  2420.9\n",
      "Epoch 0/9 Loss: 0.0285 Precision: 0.9700 Recall: 0.9733 F1 Score: 0.9717 Acc: 0.9904\n",
      "total number of batches to anticipate for epoch 1:  2420.9\n",
      "Epoch 1/9 Loss: 0.0213 Precision: 0.9751 Recall: 0.9775 F1 Score: 0.9763 Acc: 0.9920\n",
      "total number of batches to anticipate for epoch 2:  2420.9\n",
      "Epoch 2/9 Loss: 0.0167 Precision: 0.9817 Recall: 0.9834 F1 Score: 0.9825 Acc: 0.9941\n",
      "total number of batches to anticipate for epoch 3:  2420.9\n",
      "Epoch 3/9 Loss: 0.0140 Precision: 0.9846 Recall: 0.9873 F1 Score: 0.9859 Acc: 0.9952\n",
      "total number of batches to anticipate for epoch 4:  2420.9\n",
      "Epoch 4/9 Loss: 0.0134 Precision: 0.9853 Recall: 0.9860 F1 Score: 0.9857 Acc: 0.9952\n",
      "total number of batches to anticipate for epoch 5:  2420.9\n",
      "Epoch 5/9 Loss: 0.0108 Precision: 0.9873 Recall: 0.9897 F1 Score: 0.9885 Acc: 0.9961\n",
      "total number of batches to anticipate for epoch 6:  2420.9\n",
      "Epoch 6/9 Loss: 0.0101 Precision: 0.9900 Recall: 0.9909 F1 Score: 0.9905 Acc: 0.9968\n",
      "total number of batches to anticipate for epoch 7:  2420.9\n",
      "Epoch 7/9 Loss: 0.0087 Precision: 0.9907 Recall: 0.9917 F1 Score: 0.9912 Acc: 0.9970\n",
      "total number of batches to anticipate for epoch 8:  2420.9\n",
      "Epoch 8/9 Loss: 0.0104 Precision: 0.9885 Recall: 0.9895 F1 Score: 0.9890 Acc: 0.9963\n",
      "total number of batches to anticipate for epoch 9:  2420.9\n",
      "Epoch 9/9 Loss: 0.0057 Precision: 0.9951 Recall: 0.9944 F1 Score: 0.9947 Acc: 0.9982\n",
      "total number of batches to anticipate for epoch 0:  2420.9\n",
      "Epoch 0/9 Loss: 0.0674 Precision: 0.9242 Recall: 0.9312 F1 Score: 0.9277 Acc: 0.9755\n",
      "total number of batches to anticipate for epoch 1:  2420.9\n",
      "Epoch 1/9 Loss: 0.0635 Precision: 0.9213 Recall: 0.9398 F1 Score: 0.9305 Acc: 0.9763\n",
      "total number of batches to anticipate for epoch 2:  2420.9\n",
      "Epoch 2/9 Loss: 0.0582 Precision: 0.9307 Recall: 0.9427 F1 Score: 0.9367 Acc: 0.9785\n",
      "total number of batches to anticipate for epoch 3:  2420.9\n",
      "Epoch 3/9 Loss: 0.0553 Precision: 0.9346 Recall: 0.9476 F1 Score: 0.9411 Acc: 0.9800\n",
      "total number of batches to anticipate for epoch 4:  2420.9\n",
      "Epoch 4/9 Loss: 0.0515 Precision: 0.9388 Recall: 0.9506 F1 Score: 0.9447 Acc: 0.9812\n",
      "total number of batches to anticipate for epoch 5:  2420.9\n",
      "Epoch 5/9 Loss: 0.0517 Precision: 0.9345 Recall: 0.9469 F1 Score: 0.9407 Acc: 0.9798\n",
      "total number of batches to anticipate for epoch 6:  2420.9\n",
      "Epoch 6/9 Loss: 0.0488 Precision: 0.9459 Recall: 0.9540 F1 Score: 0.9499 Acc: 0.9830\n",
      "total number of batches to anticipate for epoch 7:  2420.9\n",
      "Epoch 7/9 Loss: 0.0395 Precision: 0.9531 Recall: 0.9591 F1 Score: 0.9561 Acc: 0.9851\n",
      "total number of batches to anticipate for epoch 8:  2420.9\n",
      "Epoch 8/9 Loss: 0.0484 Precision: 0.9405 Recall: 0.9515 F1 Score: 0.9460 Acc: 0.9817\n",
      "total number of batches to anticipate for epoch 9:  2420.9\n",
      "Epoch 9/9 Loss: 0.0336 Precision: 0.9589 Recall: 0.9657 F1 Score: 0.9623 Acc: 0.9872\n",
      "total number of batches to anticipate for epoch 0:  2420.9\n",
      "Epoch 0/9 Loss: 0.0211 Precision: 0.9779 Recall: 0.9741 F1 Score: 0.9760 Acc: 0.9919\n",
      "total number of batches to anticipate for epoch 1:  2420.9\n",
      "Epoch 1/9 Loss: 0.0178 Precision: 0.9810 Recall: 0.9831 F1 Score: 0.9820 Acc: 0.9939\n",
      "total number of batches to anticipate for epoch 2:  2420.9\n",
      "Epoch 2/9 Loss: 0.0143 Precision: 0.9830 Recall: 0.9883 F1 Score: 0.9856 Acc: 0.9951\n",
      "total number of batches to anticipate for epoch 3:  2420.9\n",
      "Epoch 3/9 Loss: 0.0134 Precision: 0.9844 Recall: 0.9890 F1 Score: 0.9867 Acc: 0.9955\n",
      "total number of batches to anticipate for epoch 4:  2420.9\n",
      "Epoch 4/9 Loss: 0.0118 Precision: 0.9871 Recall: 0.9907 F1 Score: 0.9889 Acc: 0.9962\n",
      "total number of batches to anticipate for epoch 5:  2420.9\n",
      "Epoch 5/9 Loss: 0.0106 Precision: 0.9902 Recall: 0.9917 F1 Score: 0.9910 Acc: 0.9969\n",
      "total number of batches to anticipate for epoch 6:  2420.9\n",
      "Epoch 6/9 Loss: 0.0107 Precision: 0.9885 Recall: 0.9887 F1 Score: 0.9886 Acc: 0.9962\n",
      "total number of batches to anticipate for epoch 7:  2420.9\n",
      "Epoch 7/9 Loss: 0.0092 Precision: 0.9907 Recall: 0.9924 F1 Score: 0.9916 Acc: 0.9971\n",
      "total number of batches to anticipate for epoch 8:  2420.9\n",
      "Epoch 8/9 Loss: 0.0103 Precision: 0.9900 Recall: 0.9895 F1 Score: 0.9897 Acc: 0.9965\n",
      "total number of batches to anticipate for epoch 9:  2420.9\n",
      "Epoch 9/9 Loss: 0.0090 Precision: 0.9910 Recall: 0.9931 F1 Score: 0.9921 Acc: 0.9973\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [50, 32, 10]\n",
    "learning_rates = [0.001, 0.01, 0.0001]\n",
    "input_images_path = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\images\\Image_Classification\\train_cropped_images\\224\")\n",
    "\n",
    "#This is where the trained models will be output to\n",
    "out_results_path = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\models\")\n",
    "\n",
    "#At this point, we should already have images sized to required_image_size from the preprocessing phase. This is just to navigate to the correct image dir.\n",
    "#It should also, therefore, correspond to the sized depicted by 'input_images_path'.\n",
    "required_image_size = 224\n",
    "target_category_name = \"pedestrian\"\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for learning_rate in learning_rates:\n",
    "        train_resnet50_classification(model_instance=model_res50, num_epochs=10, batch_size=batch_size, input_images_path=input_images_path, out_results_path=out_results_path,\n",
    "                                       required_imgage_size=required_image_size, target_category_name=target_category_name, learning_rate=learning_rate, save_per_epoch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all of the trained models back in and stich their results together into a summary \"all_model_results_df\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WARNING: The cell below will overwrite \"all_model_results.csv\" if you have alreayd created it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id_path</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>final_loss</th>\n",
       "      <th>final_accuracy</th>\n",
       "      <th>final_precision</th>\n",
       "      <th>final_recall</th>\n",
       "      <th>final_F1</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>validation_recall</th>\n",
       "      <th>validation_F1</th>\n",
       "      <th>false_positive_images</th>\n",
       "      <th>false_negative_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>model_res50_epoch_9_batchsize_10_lr_0.0001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001.</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.997315</td>\n",
       "      <td>0.990965</td>\n",
       "      <td>0.993147</td>\n",
       "      <td>0.992055</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>model_res50_epoch_9_batchsize_10_lr_0.001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001.</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.998224</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>0.994371</td>\n",
       "      <td>0.994736</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>model_res50_epoch_9_batchsize_10_lr_0.01.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01.</td>\n",
       "      <td>0.033554</td>\n",
       "      <td>0.987236</td>\n",
       "      <td>0.958931</td>\n",
       "      <td>0.965737</td>\n",
       "      <td>0.962322</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>model_res50_epoch_9_batchsize_32_lr_0.0001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001.</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.994217</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>0.984826</td>\n",
       "      <td>0.982902</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>model_res50_epoch_9_batchsize_32_lr_0.001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001.</td>\n",
       "      <td>0.012222</td>\n",
       "      <td>0.995415</td>\n",
       "      <td>0.986774</td>\n",
       "      <td>0.986050</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>model_res50_epoch_9_batchsize_32_lr_0.01.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01.</td>\n",
       "      <td>0.043471</td>\n",
       "      <td>0.984386</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.960352</td>\n",
       "      <td>0.954048</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>model_res50_epoch_9_batchsize_50_lr_0.0001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001.</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>0.986575</td>\n",
       "      <td>0.953242</td>\n",
       "      <td>0.967939</td>\n",
       "      <td>0.960534</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>model_res50_epoch_9_batchsize_50_lr_0.001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001.</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>0.989219</td>\n",
       "      <td>0.964763</td>\n",
       "      <td>0.971610</td>\n",
       "      <td>0.968175</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>model_res50_epoch_9_batchsize_50_lr_0.01.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01.</td>\n",
       "      <td>0.068964</td>\n",
       "      <td>0.974514</td>\n",
       "      <td>0.915648</td>\n",
       "      <td>0.935144</td>\n",
       "      <td>0.925294</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model_id_path epoch batch_size  \\\n",
       "81  model_res50_epoch_9_batchsize_10_lr_0.0001.pth     9         10   \n",
       "82   model_res50_epoch_9_batchsize_10_lr_0.001.pth     9         10   \n",
       "83    model_res50_epoch_9_batchsize_10_lr_0.01.pth     9         10   \n",
       "84  model_res50_epoch_9_batchsize_32_lr_0.0001.pth     9         32   \n",
       "85   model_res50_epoch_9_batchsize_32_lr_0.001.pth     9         32   \n",
       "86    model_res50_epoch_9_batchsize_32_lr_0.01.pth     9         32   \n",
       "87  model_res50_epoch_9_batchsize_50_lr_0.0001.pth     9         50   \n",
       "88   model_res50_epoch_9_batchsize_50_lr_0.001.pth     9         50   \n",
       "89    model_res50_epoch_9_batchsize_50_lr_0.01.pth     9         50   \n",
       "\n",
       "   learning_rate  final_loss  final_accuracy  final_precision  final_recall  \\\n",
       "81       0.0001.    0.008955        0.997315         0.990965      0.993147   \n",
       "82        0.001.    0.005681        0.998224         0.995102      0.994371   \n",
       "83         0.01.    0.033554        0.987236         0.958931      0.965737   \n",
       "84       0.0001.    0.016930        0.994217         0.980985      0.984826   \n",
       "85        0.001.    0.012222        0.995415         0.986774      0.986050   \n",
       "86         0.01.    0.043471        0.984386         0.947826      0.960352   \n",
       "87       0.0001.    0.035888        0.986575         0.953242      0.967939   \n",
       "88        0.001.    0.029320        0.989219         0.964763      0.971610   \n",
       "89         0.01.    0.068964        0.974514         0.915648      0.935144   \n",
       "\n",
       "    final_F1 validation_loss validation_accuracy validation_precision  \\\n",
       "81  0.992055            None                None                 None   \n",
       "82  0.994736            None                None                 None   \n",
       "83  0.962322            None                None                 None   \n",
       "84  0.982902            None                None                 None   \n",
       "85  0.986412            None                None                 None   \n",
       "86  0.954048            None                None                 None   \n",
       "87  0.960534            None                None                 None   \n",
       "88  0.968175            None                None                 None   \n",
       "89  0.925294            None                None                 None   \n",
       "\n",
       "   validation_recall validation_F1 false_positive_images false_negative_images  \n",
       "81              None          None                  None                  None  \n",
       "82              None          None                  None                  None  \n",
       "83              None          None                  None                  None  \n",
       "84              None          None                  None                  None  \n",
       "85              None          None                  None                  None  \n",
       "86              None          None                  None                  None  \n",
       "87              None          None                  None                  None  \n",
       "88              None          None                  None                  None  \n",
       "89              None          None                  None                  None  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To load the model and metrics later\n",
    "model_metrics = ['final_loss', 'final_accuracy', 'final_precision', 'final_recall', 'final_F1']\n",
    "model_dir = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\models\")\n",
    "\n",
    "all_model_results = []\n",
    "for path in os.listdir(model_dir):\n",
    "        model_results = {}\n",
    "        model_path = os.path.join(model_dir, path)\n",
    "        if model_path.endswith(\"pth\"):\n",
    "            checkpoint = torch.load(model_path)\n",
    "            matches = re.search(r'epoch_(\\d+)_batchsize_(\\d+)_lr_([\\d.]+)', model_path)\n",
    "            if matches:\n",
    "                model_results[\"model_id_name\"] = path\n",
    "                epoch = matches.group(1)\n",
    "                model_results[\"epoch\"] = epoch\n",
    "                batch_size = matches.group(2)\n",
    "                model_results[\"batch_size\"] = batch_size\n",
    "                lr = matches.group(3)\n",
    "                model_results[\"learning_rate\"] = lr\n",
    "\n",
    "            for metric in model_metrics:\n",
    "                model_results[metric] = checkpoint[metric]\n",
    "            \n",
    "            all_model_results.append(model_results)\n",
    "\n",
    "all_model_results_df = pd.DataFrame(all_model_results)\n",
    "all_model_results_df = all_model_results_df.sort_values([\"batch_size\", \"learning_rate\", \"epoch\"])\n",
    "\n",
    "#we only need to fix final_accuracy for now until we run training again. Fix this before running training again. \n",
    "all_model_results_df[\"final_accuracy\"] = all_model_results_df[\"final_accuracy\"].apply(lambda x: x.item())\n",
    "\n",
    "#Create empty columns for the validation loop to populate\n",
    "all_model_results_df[\"validation_loss\"] = None\n",
    "all_model_results_df[\"validation_accuracy\"] = None\n",
    "all_model_results_df[\"validation_precision\"] = None\n",
    "all_model_results_df[\"validation_recall\"] = None\n",
    "all_model_results_df[\"validation_F1\"] = None\n",
    "all_model_results_df[\"false_positive_images\"] = None\n",
    "all_model_results_df[\"false_negative_images\"] = None\n",
    "\n",
    "#Set these to 'object' type so we can assign a list of strings converted into one, large string.\n",
    "all_model_results_df['false_positive_images'] = all_model_results_df['false_positive_images'].astype('object')\n",
    "all_model_results_df['false_positive_images'] = all_model_results_df['false_positive_images'].astype('object')\n",
    "\n",
    "\n",
    "#Write all_model_results_df to disk\n",
    "all_model_results_df.to_csv(os.path.join(model_dir, \"all_model_results.csv\"))\n",
    "\n",
    "final_epoch_results = all_model_results_df[all_model_results_df[\"epoch\"] == 9]\n",
    "final_epoch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id_path</th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>final_loss</th>\n",
       "      <th>final_accuracy</th>\n",
       "      <th>final_precision</th>\n",
       "      <th>final_recall</th>\n",
       "      <th>final_F1</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>validation_recall</th>\n",
       "      <th>validation_F1</th>\n",
       "      <th>false_positive_images</th>\n",
       "      <th>false_negative_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model_res50_epoch_9_batchsize_10_lr_0.0001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001.</td>\n",
       "      <td>0.008955</td>\n",
       "      <td>0.997315</td>\n",
       "      <td>0.990965</td>\n",
       "      <td>0.993147</td>\n",
       "      <td>0.992055</td>\n",
       "      <td>0.091312</td>\n",
       "      <td>0.972572</td>\n",
       "      <td>0.866940</td>\n",
       "      <td>0.930258</td>\n",
       "      <td>0.897483</td>\n",
       "      <td>['cropped_host-a102_cam5_1242754969332234006_1...</td>\n",
       "      <td>['cropped_host-a011_cam2_1233688946717605006_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>model_res50_epoch_9_batchsize_10_lr_0.001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001.</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.998224</td>\n",
       "      <td>0.995102</td>\n",
       "      <td>0.994371</td>\n",
       "      <td>0.994736</td>\n",
       "      <td>0.159119</td>\n",
       "      <td>0.962968</td>\n",
       "      <td>0.800370</td>\n",
       "      <td>0.950027</td>\n",
       "      <td>0.868801</td>\n",
       "      <td>['cropped_host-a007_cam3_1231093059199360006_5...</td>\n",
       "      <td>['cropped_host-a011_cam0_1232752780051142006_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>model_res50_epoch_9_batchsize_10_lr_0.01.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01.</td>\n",
       "      <td>0.033554</td>\n",
       "      <td>0.987236</td>\n",
       "      <td>0.958931</td>\n",
       "      <td>0.965737</td>\n",
       "      <td>0.962322</td>\n",
       "      <td>0.089225</td>\n",
       "      <td>0.970375</td>\n",
       "      <td>0.863472</td>\n",
       "      <td>0.915157</td>\n",
       "      <td>0.888563</td>\n",
       "      <td>['cropped_host-a101_cam1_1242748999766305006_6...</td>\n",
       "      <td>['cropped_host-a011_cam0_1232752781651142006_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>model_res50_epoch_9_batchsize_32_lr_0.0001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001.</td>\n",
       "      <td>0.016930</td>\n",
       "      <td>0.994217</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>0.984826</td>\n",
       "      <td>0.982902</td>\n",
       "      <td>0.091628</td>\n",
       "      <td>0.969630</td>\n",
       "      <td>0.841383</td>\n",
       "      <td>0.942339</td>\n",
       "      <td>0.889004</td>\n",
       "      <td>['cropped_host-a101_cam6_1240875137450000006_9...</td>\n",
       "      <td>['cropped_host-a101_cam6_1240875138650000006_7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>model_res50_epoch_9_batchsize_32_lr_0.001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.001.</td>\n",
       "      <td>0.012222</td>\n",
       "      <td>0.995415</td>\n",
       "      <td>0.986774</td>\n",
       "      <td>0.986050</td>\n",
       "      <td>0.986412</td>\n",
       "      <td>0.162003</td>\n",
       "      <td>0.961196</td>\n",
       "      <td>0.795407</td>\n",
       "      <td>0.941516</td>\n",
       "      <td>0.862316</td>\n",
       "      <td>['cropped_host-a101_cam6_1240875147050000006_2...</td>\n",
       "      <td>['cropped_host-a004_cam0_1232923267651064006_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>model_res50_epoch_9_batchsize_32_lr_0.01.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>0.01.</td>\n",
       "      <td>0.043471</td>\n",
       "      <td>0.984386</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.960352</td>\n",
       "      <td>0.954048</td>\n",
       "      <td>0.074976</td>\n",
       "      <td>0.971012</td>\n",
       "      <td>0.862423</td>\n",
       "      <td>0.922570</td>\n",
       "      <td>0.891483</td>\n",
       "      <td>['cropped_host-a101_cam4_1240875154416660006_b...</td>\n",
       "      <td>['cropped_host-a004_cam1_1235947105534300006_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>model_res50_epoch_9_batchsize_50_lr_0.0001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0001.</td>\n",
       "      <td>0.035888</td>\n",
       "      <td>0.986575</td>\n",
       "      <td>0.953242</td>\n",
       "      <td>0.967939</td>\n",
       "      <td>0.960534</td>\n",
       "      <td>0.080530</td>\n",
       "      <td>0.971615</td>\n",
       "      <td>0.861175</td>\n",
       "      <td>0.929984</td>\n",
       "      <td>0.894257</td>\n",
       "      <td>['cropped_host-a101_cam6_1240875137450000006_9...</td>\n",
       "      <td>['cropped_host-a011_cam3_1236104051500995006_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>model_res50_epoch_9_batchsize_50_lr_0.001.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001.</td>\n",
       "      <td>0.029320</td>\n",
       "      <td>0.989219</td>\n",
       "      <td>0.964763</td>\n",
       "      <td>0.971610</td>\n",
       "      <td>0.968175</td>\n",
       "      <td>0.089566</td>\n",
       "      <td>0.971119</td>\n",
       "      <td>0.847212</td>\n",
       "      <td>0.947007</td>\n",
       "      <td>0.894334</td>\n",
       "      <td>['cropped_host-a102_cam3_1242754977999260006_d...</td>\n",
       "      <td>['cropped_host-a011_cam5_1232752550067719006_7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>model_res50_epoch_9_batchsize_50_lr_0.01.pth</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01.</td>\n",
       "      <td>0.068964</td>\n",
       "      <td>0.974514</td>\n",
       "      <td>0.915648</td>\n",
       "      <td>0.935144</td>\n",
       "      <td>0.925294</td>\n",
       "      <td>0.114841</td>\n",
       "      <td>0.956058</td>\n",
       "      <td>0.759732</td>\n",
       "      <td>0.964580</td>\n",
       "      <td>0.849988</td>\n",
       "      <td>['cropped_host-a101_cam2_1242749002782945006_6...</td>\n",
       "      <td>['cropped_host-a101_cam0_1242748836349526006_2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     model_id_path  epoch  batch_size  \\\n",
       "9   model_res50_epoch_9_batchsize_10_lr_0.0001.pth      9          10   \n",
       "19   model_res50_epoch_9_batchsize_10_lr_0.001.pth      9          10   \n",
       "29    model_res50_epoch_9_batchsize_10_lr_0.01.pth      9          10   \n",
       "39  model_res50_epoch_9_batchsize_32_lr_0.0001.pth      9          32   \n",
       "49   model_res50_epoch_9_batchsize_32_lr_0.001.pth      9          32   \n",
       "59    model_res50_epoch_9_batchsize_32_lr_0.01.pth      9          32   \n",
       "69  model_res50_epoch_9_batchsize_50_lr_0.0001.pth      9          50   \n",
       "79   model_res50_epoch_9_batchsize_50_lr_0.001.pth      9          50   \n",
       "89    model_res50_epoch_9_batchsize_50_lr_0.01.pth      9          50   \n",
       "\n",
       "   learning_rate  final_loss  final_accuracy  final_precision  final_recall  \\\n",
       "9        0.0001.    0.008955        0.997315         0.990965      0.993147   \n",
       "19        0.001.    0.005681        0.998224         0.995102      0.994371   \n",
       "29         0.01.    0.033554        0.987236         0.958931      0.965737   \n",
       "39       0.0001.    0.016930        0.994217         0.980985      0.984826   \n",
       "49        0.001.    0.012222        0.995415         0.986774      0.986050   \n",
       "59         0.01.    0.043471        0.984386         0.947826      0.960352   \n",
       "69       0.0001.    0.035888        0.986575         0.953242      0.967939   \n",
       "79        0.001.    0.029320        0.989219         0.964763      0.971610   \n",
       "89         0.01.    0.068964        0.974514         0.915648      0.935144   \n",
       "\n",
       "    final_F1  validation_loss  validation_accuracy  validation_precision  \\\n",
       "9   0.992055         0.091312             0.972572              0.866940   \n",
       "19  0.994736         0.159119             0.962968              0.800370   \n",
       "29  0.962322         0.089225             0.970375              0.863472   \n",
       "39  0.982902         0.091628             0.969630              0.841383   \n",
       "49  0.986412         0.162003             0.961196              0.795407   \n",
       "59  0.954048         0.074976             0.971012              0.862423   \n",
       "69  0.960534         0.080530             0.971615              0.861175   \n",
       "79  0.968175         0.089566             0.971119              0.847212   \n",
       "89  0.925294         0.114841             0.956058              0.759732   \n",
       "\n",
       "    validation_recall  validation_F1  \\\n",
       "9            0.930258       0.897483   \n",
       "19           0.950027       0.868801   \n",
       "29           0.915157       0.888563   \n",
       "39           0.942339       0.889004   \n",
       "49           0.941516       0.862316   \n",
       "59           0.922570       0.891483   \n",
       "69           0.929984       0.894257   \n",
       "79           0.947007       0.894334   \n",
       "89           0.964580       0.849988   \n",
       "\n",
       "                                false_positive_images  \\\n",
       "9   ['cropped_host-a102_cam5_1242754969332234006_1...   \n",
       "19  ['cropped_host-a007_cam3_1231093059199360006_5...   \n",
       "29  ['cropped_host-a101_cam1_1242748999766305006_6...   \n",
       "39  ['cropped_host-a101_cam6_1240875137450000006_9...   \n",
       "49  ['cropped_host-a101_cam6_1240875147050000006_2...   \n",
       "59  ['cropped_host-a101_cam4_1240875154416660006_b...   \n",
       "69  ['cropped_host-a101_cam6_1240875137450000006_9...   \n",
       "79  ['cropped_host-a102_cam3_1242754977999260006_d...   \n",
       "89  ['cropped_host-a101_cam2_1242749002782945006_6...   \n",
       "\n",
       "                                false_negative_images  \n",
       "9   ['cropped_host-a011_cam2_1233688946717605006_b...  \n",
       "19  ['cropped_host-a011_cam0_1232752780051142006_d...  \n",
       "29  ['cropped_host-a011_cam0_1232752781651142006_a...  \n",
       "39  ['cropped_host-a101_cam6_1240875138650000006_7...  \n",
       "49  ['cropped_host-a004_cam0_1232923267651064006_d...  \n",
       "59  ['cropped_host-a004_cam1_1235947105534300006_e...  \n",
       "69  ['cropped_host-a011_cam3_1236104051500995006_1...  \n",
       "79  ['cropped_host-a011_cam5_1232752550067719006_7...  \n",
       "89  ['cropped_host-a101_cam0_1242748836349526006_2...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\models\")\n",
    "all_model_results_df = pd.read_csv(os.path.join(model_dir, \"all_model_results.csv\"))\n",
    "all_model_results_df\n",
    "final_epoch_results = all_model_results_df[all_model_results_df[\"epoch\"] == 9]\n",
    "final_epoch_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the model training went as expected, you should hopefully end up with output looking similar to the text below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_id_path\\tepoch\\tbatch_size\\tlearning_rate\\tfinal_loss\\tfinal_accuracy\\tfinal_precision\\tfinal_recall\\tfinal_F1\\tvalidation_loss\\tvalidation_accuracy\\tvalidation_precision\\tvalidation_recall\\tvalidation_F1\\tfalse_positive_images\\tfalse_negative_images\\n81\\tmodel_res50_epoch_9_batchsize_10_lr_0.0001.pth\\t9\\t10\\t0.0001.\\t0.008955\\t0.997315\\t0.990965\\t0.993147\\t0.992055\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n82\\tmodel_res50_epoch_9_batchsize_10_lr_0.001.pth\\t9\\t10\\t0.001.\\t0.005681\\t0.998224\\t0.995102\\t0.994371\\t0.994736\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n83\\tmodel_res50_epoch_9_batchsize_10_lr_0.01.pth\\t9\\t10\\t0.01.\\t0.033554\\t0.987236\\t0.958931\\t0.965737\\t0.962322\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n84\\tmodel_res50_epoch_9_batchsize_32_lr_0.0001.pth\\t9\\t32\\t0.0001.\\t0.016930\\t0.994217\\t0.980985\\t0.984826\\t0.982902\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n85\\tmodel_res50_epoch_9_batchsize_32_lr_0.001.pth\\t9\\t32\\t0.001.\\t0.012222\\t0.995415\\t0.986774\\t0.986050\\t0.986412\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n86\\tmodel_res50_epoch_9_batchsize_32_lr_0.01.pth\\t9\\t32\\t0.01.\\t0.043471\\t0.984386\\t0.947826\\t0.960352\\t0.954048\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n87\\tmodel_res50_epoch_9_batchsize_50_lr_0.0001.pth\\t9\\t50\\t0.0001.\\t0.035888\\t0.986575\\t0.953242\\t0.967939\\t0.960534\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n88\\tmodel_res50_epoch_9_batchsize_50_lr_0.001.pth\\t9\\t50\\t0.001.\\t0.029320\\t0.989219\\t0.964763\\t0.971610\\t0.968175\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n89\\tmodel_res50_epoch_9_batchsize_50_lr_0.01.pth\\t9\\t50\\t0.01.\\t0.068964\\t0.974514\\t0.915648\\t0.935144\\t0.925294\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\tNone\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "model_id_name\tepoch\tbatch_size\tlearning_rate\tfinal_loss\tfinal_accuracy\tfinal_precision\tfinal_recall\tfinal_F1\tvalidation_loss\tvalidation_accuracy\tvalidation_precision\tvalidation_recall\tvalidation_F1\tfalse_positive_images\tfalse_negative_images\n",
    "81\tmodel_res50_epoch_9_batchsize_10_lr_0.0001.pth\t9\t10\t0.0001.\t0.008955\t0.997315\t0.990965\t0.993147\t0.992055\tNone\tNone\tNone\tNone\tNone\tNone\tNone\n",
    "82\tmodel_res50_epoch_9_batchsize_10_lr_0.001.pth\t9\t10\t0.001.\t0.005681\t0.998224\t0.995102\t0.994371\t0.994736\tNone\tNone\tNone\tNone\tNone\tNone\tNone\n",
    "83\tmodel_res50_epoch_9_batchsize_10_lr_0.01.pth\t9\t10\t0.01.\t0.033554\t0.987236\t0.958931\t0.965737\t0.962322\tNone\tNone\tNone\tNone\tNone\tNone\tNone\n",
    "84\tmodel_res50_epoch_9_batchsize_32_lr_0.0001.pth\t9\t32\t0.0001.\t0.016930\t0.994217\t0.980985\t0.984826\t0.982902\tNone\tNone\tNone\tNone\tNone\tNone\tNone\n",
    "85\tmodel_res50_epoch_9_batchsize_32_lr_0.001.pth\t9\t32\t0.001.\t0.012222\t0.995415\t0.986774\t0.986050\t0.986412\tNone\tNone\tNone\tNone\tNone\tNone\tNone\n",
    "86\tmodel_res50_epoch_9_batchsize_32_lr_0.01.pth\t9\t32\t0.01.\t0.043471\t0.984386\t0.947826\t0.960352\t0.954048\tNone\tNone\tNone\tNone\tNone\tNone\tNone\n",
    "87\tmodel_res50_epoch_9_batchsize_50_lr_0.0001.pth\t9\t50\t0.0001.\t0.035888\t0.986575\t0.953242\t0.967939\t0.960534\tNone\tNone\tNone\tNone\tNone\tNone\tNone\n",
    "88\tmodel_res50_epoch_9_batchsize_50_lr_0.001.pth\t9\t50\t0.001.\t0.029320\t0.989219\t0.964763\t0.971610\t0.968175\tNone\tNone\tNone\tNone\tNone\tNone\tNone\n",
    "89\tmodel_res50_epoch_9_batchsize_50_lr_0.01.pth\t9\t50\t0.01.\t0.068964\t0.974514\t0.915648\t0.935144\t0.925294\tNone\tNone\tNone\tNone\tNone\tNone\tNone\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation/Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_resnet50_classification(model_checkpoint, model_name_id, validation_images_dir, training_records_df_path, required_imgage_size=224, target_category_name=\"pedestrian\",\n",
    "                                  criterion=nn.CrossEntropyLoss()):\n",
    "    \"\"\"\n",
    "    Performs validation of a ResNet50 model on a specified dataset and records the metrics.\n",
    "\n",
    "    This function takes a trained model checkpoint, performs validation on a given dataset, and records various metrics like loss, accuracy, precision, recall, and F1 score. \n",
    "    It also identifies false positive and false negative images and records them.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_checkpoint: The saved model checkpoint containing the state dictionary of the trained ResNet50 model.\n",
    "    model_name_id (str): Identifier for the model, used to match and record results in the training records DataFrame.\n",
    "    validation_images_dir (str): Path to the directory containing validation images.\n",
    "    training_records_df_path (str): Path to the CSV file where training records are stored and where validation results will be appended.\n",
    "    required_imgage_size (int, optional): Size that input images are expected to be in. Default is 224.\n",
    "    target_category_name (str, optional): The target category for classification. Default is \"pedestrian\".\n",
    "    criterion: Loss function used for validation. Default is `nn.CrossEntropyLoss()`.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function assumes the presence of a pre-trained model and a DataFrame (in CSV format) containing training records.\n",
    "    - Validation involves processing images through the model, calculating loss and other metrics.\n",
    "    - The function records the validation results (loss, accuracy, precision, recall, F1 score) in the training records DataFrame.\n",
    "    - Additionally, it identifies and records the paths of false positive and false negative images.\n",
    "    - The updated DataFrame with training and validation records is saved back to the specified path.\n",
    "    - This function is designed to work with a binary classification setting.\n",
    "    - It assumes that the input images are organized in a way that is compatible with the `Lyft_image_classification_CustomDataset` class.\n",
    "    \"\"\"\n",
    "\n",
    "    training_records_df = pd.read_csv(training_records_df_path).drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "    #Create a fresh model instance and then import its state from the model_checkpoint.\n",
    "    model_res50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "    num_ftrs = model_res50.fc.in_features\n",
    "    # Modify the last layer for binary classification. This is because this was the architecture which was used for the training model.\n",
    "    model_res50.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "    #Load the state into the model instance.\n",
    "    model_res50.load_state_dict(model_checkpoint['model_state_dict'])\n",
    "    # Move model to device and set the model to evaluation mode\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model_res50.to(device)\n",
    "    model_res50.eval()\n",
    "\n",
    "    #Creat instances of our custom Dataset and subsequent default Dataloader\n",
    "    dataset = Lyft_image_classification_CustomDataset(validation_images_dir, target_category_name, required_imgage_size)\n",
    "    row_index = training_records_df[training_records_df[\"model_id_path\"] == model_name_id].index\n",
    "    batch_size = int(training_records_df.loc[row_index, \"batch_size\"].iloc[0])\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    #Initialize metrics\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total_samples = 0\n",
    "    running_true_positives = 0\n",
    "    running_false_positives = 0\n",
    "    running_false_negatives = 0\n",
    "\n",
    "    #Holders for the incorrect prediction image paths.\n",
    "    false_positive_images = []\n",
    "    false_negative_images = []\n",
    "\n",
    "    # Disable gradient calculations as they are not needed for validation\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, image_names in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_res50(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total_samples += labels.size(0)\n",
    "            # Calculate True Positives, False Positives, False Negatives\n",
    "            for i in range(len(labels)):\n",
    "                if preds[i] == labels[i] == 1:  # True Positive\n",
    "                    running_true_positives += 1\n",
    "                elif preds[i] == 1 and labels[i] == 0:  # False Positive\n",
    "                    running_false_positives += 1\n",
    "                    false_positive_images.append(image_names[i])\n",
    "                elif preds[i] == 0 and labels[i] == 1:  # False Negative\n",
    "                    running_false_negatives += 1\n",
    "                    false_negative_images.append(image_names[i])\n",
    "\n",
    "\n",
    "    # Calculate the average loss and accuracy over the validation set\n",
    "    val_loss = running_loss / total_samples\n",
    "    val_acc = running_corrects.double() / total_samples\n",
    "    val_acc = val_acc.item()\n",
    "    # Calculate Precision, Recall, and F1 Score after the loop\n",
    "    precision = running_true_positives / (running_true_positives + running_false_positives) if (running_true_positives + running_false_positives) > 0 else 0\n",
    "    recall = running_true_positives / (running_true_positives + running_false_negatives) if (running_true_positives + running_false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(f'Validation Loss: {val_loss:.4f} Precision: {precision:.4f} Recall: {recall:.4f} F1 Score: {f1_score:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "    #Write the validation output to the corresponding row/col of training_records_df\n",
    "    # Reminder: training_records_df[condition][\"column\"] = value can lead to a SettingWithCopyWarning in pandas.\n",
    "    # Find the row index, and use .loc[] instead.\n",
    "    row_index = training_records_df[training_records_df[\"model_id_path\"] == model_name_id].index\n",
    "    training_records_df.loc[row_index, \"validation_loss\"] = val_loss\n",
    "    training_records_df.loc[row_index, \"validation_accuracy\"] = val_acc\n",
    "    training_records_df.loc[row_index, \"validation_precision\"] = precision\n",
    "    training_records_df.loc[row_index, \"validation_recall\"] = recall\n",
    "    training_records_df.loc[row_index, \"validation_F1\"] = f1_score\n",
    "    \n",
    "    false_positive_images_str = str(false_positive_images)\n",
    "    false_negative_images_str = str(false_negative_images)\n",
    "    training_records_df.loc[row_index, \"false_positive_images\"] = false_positive_images_str\n",
    "    training_records_df.loc[row_index, \"false_negative_images\"] = false_negative_images_str\n",
    "\n",
    "    training_records_df.to_csv(training_records_df_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_validate = list(final_epoch_results[\"model_id_path\"].values)\n",
    "model_dir = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\models\")\n",
    "validation_images_dir = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\images\\Image_Classification\\validation_cropped_images\\224\")\n",
    "training_records_df_path = os.path.join(model_dir, \"all_model_results.csv\")\n",
    "required_imgage_size = 224\n",
    "target_category_name = \"pedestrian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you do not want to perform Validation and want to skip to the validation results that come with the reporistory, you may skip the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in models_to_validate:\n",
    "    print(model_name)\n",
    "    checkpoint = torch.load(os.path.join(model_dir, model_name))\n",
    "    validate_resnet50_classification(checkpoint, model_name, validation_images_dir, training_records_df_path, required_imgage_size, target_category_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation/Inference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_results_df = pd.read_csv(training_records_df_path).drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "validation_results_df = validation_results_df[validation_results_df[\"epoch\"] == 9]\n",
    "# Convert string representations to actual lists\n",
    "validation_results_df['false_positive_images'] = validation_results_df['false_positive_images'].apply(ast.literal_eval)\n",
    "validation_results_df['false_negative_images'] = validation_results_df['false_negative_images'].apply(ast.literal_eval)\n",
    "validation_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score heatmap. Each box in our heatmap corresponds to the F1 Score of model that was trained with the ith-jth hyper parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Code below generated with ChatGPT 4\n",
    "# Pivot the DataFrame to create a grid\n",
    "pivot_df = validation_results_df.pivot(index='batch_size', columns='learning_rate', values='validation_F1')\n",
    "\n",
    "# Creating the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Using numpy to create an array of the pivot data\n",
    "data_array = pivot_df.to_numpy()\n",
    "\n",
    "# The columns and rows to display\n",
    "col_labels = pivot_df.columns.values\n",
    "row_labels = pivot_df.index.values\n",
    "\n",
    "# Creating the plot\n",
    "c = plt.pcolormesh(data_array, cmap='RdPu', shading='auto')\n",
    "\n",
    "# Adding color bar\n",
    "plt.colorbar(c)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title('F1 Score Heatmap by Batch Size and Learning Rate')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Batch Size')\n",
    "\n",
    "# Adjusting the ticks to be at the center of each cell\n",
    "plt.xticks(np.arange(0.5, len(col_labels), 1), col_labels, rotation=45)\n",
    "plt.yticks(np.arange(0.5, len(row_labels), 1), row_labels)\n",
    "\n",
    "# Add text annotations\n",
    "for (i, j), val in np.ndenumerate(data_array):\n",
    "    plt.text(j + 0.5, i + 0.5, f\"{val:.4f}\", ha='center', va='center', color='black')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's explore which images our model wrongly classified as Pedestrian and which images it wrongly classified as non-pedestrian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def false_positive_negative_finder(images_path, false_positive_negative_counts, print_sample_images=True):\n",
    "    \"\"\"\n",
    "    Analyzes and aggregates the count of false positives or false negatives by category,\n",
    "    and optionally displays the first three images of each category using the PIL Image class.\n",
    "\n",
    "    This function traverses through a directory structure to find specific image files \n",
    "    and counts the occurrence of each category based on the provided false positive or \n",
    "    false negative counts. If 'print_sample_images' is set to True, it also displays the \n",
    "    first three images in each category.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    images_path (str): The base path where images are stored in categorized subdirectories.\n",
    "    false_positive_negative_counts (dict): A dictionary where keys are image names and values are \n",
    "                                  counts of false positives or false negatives for those images.\n",
    "    print_sample_images (bool, optional): If True, displays the first three images for each category. Default is True.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame: A DataFrame with two columns - 'Category' and 'Count'. Each row represents \n",
    "                      a category and the number of times it was incorrectly classified \n",
    "                      (either as a false positive or false negative).\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function expects images to be stored in a specific directory structure: \n",
    "      'images_path' should contain subdirectories for each category, and each subdirectory \n",
    "      should contain the respective images.\n",
    "    - The image names in 'false_positive_negative_counts' should correspond to the actual image files, \n",
    "      minus the file extension.\n",
    "    - The function uses regex to extract the category name from the file path. It is designed \n",
    "      to work with a specific path format and may need adjustments for different directory structures.\n",
    "    - If a file is not found in the expected subdirectories, a message is printed to indicate this.\n",
    "    - When 'print_sample_images' is True, the first three images of each category are displayed using \n",
    "      the PIL Image class and matplotlib.\n",
    "    \"\"\"\n",
    "    \n",
    "    category_counts = {}\n",
    "    sample_images = {category: [] for category in category_counts}\n",
    "\n",
    "    for image_name, image_count in false_positive_negative_counts.items():\n",
    "        # Iterate over the subdirectories in the base path\n",
    "        for subdir in os.listdir(images_path):\n",
    "            subdir_path = os.path.join(images_path, subdir)\n",
    "            \n",
    "            # Check if the path is a directory\n",
    "            if os.path.isdir(subdir_path):\n",
    "                # Construct the potential full path of the file\n",
    "                potential_file_path = os.path.join(subdir_path, image_name + \".jpeg\")\n",
    "                # Check if the file exists at this path\n",
    "                if os.path.isfile(potential_file_path):\n",
    "                    match = re.search(r'validation_cropped_images\\\\(\\d+)\\\\([^\\\\]+)\\\\', potential_file_path)\n",
    "                    if match:\n",
    "                        category_name = match.group(2)\n",
    "                        if category_name in category_counts:\n",
    "                            category_counts[category_name] += 1\n",
    "                            if len(sample_images[category_name]) < 3:\n",
    "                                sample_images[category_name].append(potential_file_path)\n",
    "                        else:\n",
    "                            category_counts[category_name] = 1\n",
    "                            sample_images[category_name] = [potential_file_path]\n",
    "            else:\n",
    "                print(f\"File {image_name} not found in the immediate subdirectories of {subdir_path}.\")\n",
    "\n",
    "    # Sorting and optionally displaying sample images\n",
    "    category_counts_df = pd.DataFrame.from_dict(category_counts, orient=\"index\", columns=['Count'])\n",
    "    category_counts_df = category_counts_df.reset_index().rename(columns={'index': 'Category'}).sort_values(\"Count\", ascending=False)\n",
    "\n",
    "    if print_sample_images:\n",
    "        for category, images in sample_images.items():\n",
    "            print(f\"\\nCategory: {category}\")\n",
    "            for img_path in images:\n",
    "                print(f\"Displaying Image: {img_path}\")\n",
    "                img = Image.open(img_path)\n",
    "                plt.imshow(img)\n",
    "                plt.show()\n",
    "\n",
    "    return category_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'validation_results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m false_positive_images \u001b[38;5;241m=\u001b[39m [img \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvalidation_results_df\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse_positive_images\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[0;32m      2\u001b[0m false_positive_counts \u001b[38;5;241m=\u001b[39m Counter(false_positive_images)\n\u001b[0;32m      4\u001b[0m false_negative_images \u001b[38;5;241m=\u001b[39m [img \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m validation_results_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse_negative_images\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m sublist]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'validation_results_df' is not defined"
     ]
    }
   ],
   "source": [
    "false_positive_images = [img for sublist in validation_results_df[\"false_positive_images\"] for img in sublist]\n",
    "false_positive_counts = Counter(false_positive_images)\n",
    "\n",
    "false_negative_images = [img for sublist in validation_results_df[\"false_negative_images\"] for img in sublist]\n",
    "false_negative_counts = Counter(false_negative_images)\n",
    "\n",
    "images_path = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\images\\Image_Classification\\validation_cropped_images\\224\")\n",
    "\n",
    "#Set print_sample_images to True if you want to see some examples of incorrectly classified images.\n",
    "test_false_pos_classes = false_positive_negative_finder(images_path, false_positive_counts, print_sample_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bicycle</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>truck</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other_vehicle</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bus</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>emergency</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>motorcycle</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Category  Count\n",
       "3        bicycle    882\n",
       "1          truck    342\n",
       "0  other_vehicle    249\n",
       "2            bus    155\n",
       "5      emergency     16\n",
       "4     motorcycle     10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_false_pos_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize our model's incorrect predictions by object category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hole": 0.3,
         "hovertemplate": "Category=%{label}<br>Count=%{value}<extra></extra>",
         "labels": [
          "bicycle",
          "truck",
          "other_vehicle",
          "bus",
          "emergency",
          "motorcycle"
         ],
         "legendgroup": "",
         "name": "",
         "showlegend": true,
         "type": "pie",
         "values": [
          882,
          342,
          249,
          155,
          16,
          10
         ]
        }
       ],
       "layout": {
        "height": 600,
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "False positive categories incorrectly classified as Pedestrian"
        },
        "width": 600
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the pie chart\n",
    "fig_false_positives = px.pie(test_false_pos_classes, names='Category', values='Count', \n",
    "             title=\"False positive categories incorrectly classified as Pedestrian\",\n",
    "             hole=0.3)  # Optional: creates a donut-like pie chart\n",
    "\n",
    "# Adjust the aspect ratio to make the plot more square\n",
    "fig_false_positives.update_layout(width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lastly, before switching over to Object Detection, lets visualize the first Convolutional layer of one of our trained models. There is no particular reason for doing this, but I wanted to add it to the workflow for educational purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will have to create a model instance and load our checkpoint into it. Let's just choose the model with the highest F1 score, but you could pick any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a fresh model instance and then import its state from the model_checkpoint.\n",
    "model_res50 = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model_res50.fc.in_features\n",
    "# Modify the last layer for binary classification. This is because this was the architecture which was used for the training model.\n",
    "model_res50.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "training_records_df = pd.read_csv(training_records_df_path).drop(columns=['Unnamed: 0'], errors='ignore')\n",
    "max_f1_model = training_records_df[\"validation_F1\"].idxmax()\n",
    "model_choice = training_records_df.loc[max_f1_model][\"model_id_path\"]\n",
    "\n",
    "#Load the state into the model instance.\n",
    "model_dir = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\models\")\n",
    "model_checkpoint = torch.load(os.path.join(model_dir, model_choice))\n",
    "model_res50.load_state_dict(model_checkpoint['model_state_dict'])\n",
    "#print out the contents of the model. We will display the very first layer below.\n",
    "model_res50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the output of the first layer which is a convolution layer with kernel 7x7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6077, 0.5518, 0.5796, 0.5976, 0.6440, 0.6634, 0.6656],\n",
      "         [0.6394, 0.5745, 0.5799, 0.5696, 0.6486, 0.7045, 0.6843],\n",
      "         [0.6711, 0.6032, 0.5895, 0.5740, 0.6657, 0.7130, 0.6840],\n",
      "         [0.6164, 0.5533, 0.5666, 0.5544, 0.6394, 0.6668, 0.6448],\n",
      "         [0.5606, 0.4905, 0.5030, 0.4661, 0.5461, 0.5912, 0.5932],\n",
      "         [0.5787, 0.5157, 0.5690, 0.5412, 0.5792, 0.6103, 0.6136],\n",
      "         [0.5293, 0.4745, 0.5165, 0.5084, 0.5494, 0.5956, 0.6252]],\n",
      "\n",
      "        [[0.4596, 0.3862, 0.4135, 0.4489, 0.5084, 0.5719, 0.5956],\n",
      "         [0.4798, 0.3699, 0.3779, 0.3844, 0.4921, 0.6220, 0.6263],\n",
      "         [0.4980, 0.3552, 0.3509, 0.3715, 0.5282, 0.6406, 0.6344],\n",
      "         [0.4294, 0.3078, 0.3258, 0.3501, 0.5065, 0.5995, 0.5997],\n",
      "         [0.4090, 0.2759, 0.2969, 0.2764, 0.4154, 0.5212, 0.5397],\n",
      "         [0.4783, 0.3881, 0.4482, 0.4430, 0.5032, 0.5740, 0.5782],\n",
      "         [0.4497, 0.3879, 0.4508, 0.4627, 0.5128, 0.5905, 0.6141]],\n",
      "\n",
      "        [[0.5628, 0.5297, 0.5561, 0.5796, 0.6286, 0.6583, 0.6659],\n",
      "         [0.5725, 0.5509, 0.5656, 0.5647, 0.6275, 0.6994, 0.6898],\n",
      "         [0.5790, 0.5483, 0.5499, 0.5661, 0.6515, 0.7206, 0.7013],\n",
      "         [0.5447, 0.5266, 0.5372, 0.5509, 0.6362, 0.6889, 0.6667],\n",
      "         [0.5212, 0.5022, 0.5249, 0.5272, 0.5849, 0.6268, 0.6100],\n",
      "         [0.5625, 0.5443, 0.6040, 0.6034, 0.6327, 0.6523, 0.6345],\n",
      "         [0.5365, 0.5194, 0.5861, 0.5940, 0.6385, 0.6653, 0.6665]]])\n",
      "tensor([[[0.6077, 0.4596, 0.5628],\n",
      "         [0.5518, 0.3862, 0.5297],\n",
      "         [0.5796, 0.4135, 0.5561],\n",
      "         [0.5976, 0.4489, 0.5796],\n",
      "         [0.6440, 0.5084, 0.6286],\n",
      "         [0.6634, 0.5719, 0.6583],\n",
      "         [0.6656, 0.5956, 0.6659]],\n",
      "\n",
      "        [[0.6394, 0.4798, 0.5725],\n",
      "         [0.5745, 0.3699, 0.5509],\n",
      "         [0.5799, 0.3779, 0.5656],\n",
      "         [0.5696, 0.3844, 0.5647],\n",
      "         [0.6486, 0.4921, 0.6275],\n",
      "         [0.7045, 0.6220, 0.6994],\n",
      "         [0.6843, 0.6263, 0.6898]],\n",
      "\n",
      "        [[0.6711, 0.4980, 0.5790],\n",
      "         [0.6032, 0.3552, 0.5483],\n",
      "         [0.5895, 0.3509, 0.5499],\n",
      "         [0.5740, 0.3715, 0.5661],\n",
      "         [0.6657, 0.5282, 0.6515],\n",
      "         [0.7130, 0.6406, 0.7206],\n",
      "         [0.6840, 0.6344, 0.7013]],\n",
      "\n",
      "        [[0.6164, 0.4294, 0.5447],\n",
      "         [0.5533, 0.3078, 0.5266],\n",
      "         [0.5666, 0.3258, 0.5372],\n",
      "         [0.5544, 0.3501, 0.5509],\n",
      "         [0.6394, 0.5065, 0.6362],\n",
      "         [0.6668, 0.5995, 0.6889],\n",
      "         [0.6448, 0.5997, 0.6667]],\n",
      "\n",
      "        [[0.5606, 0.4090, 0.5212],\n",
      "         [0.4905, 0.2759, 0.5022],\n",
      "         [0.5030, 0.2969, 0.5249],\n",
      "         [0.4661, 0.2764, 0.5272],\n",
      "         [0.5461, 0.4154, 0.5849],\n",
      "         [0.5912, 0.5212, 0.6268],\n",
      "         [0.5932, 0.5397, 0.6100]],\n",
      "\n",
      "        [[0.5787, 0.4783, 0.5625],\n",
      "         [0.5157, 0.3881, 0.5443],\n",
      "         [0.5690, 0.4482, 0.6040],\n",
      "         [0.5412, 0.4430, 0.6034],\n",
      "         [0.5792, 0.5032, 0.6327],\n",
      "         [0.6103, 0.5740, 0.6523],\n",
      "         [0.6136, 0.5782, 0.6345]],\n",
      "\n",
      "        [[0.5293, 0.4497, 0.5365],\n",
      "         [0.4745, 0.3879, 0.5194],\n",
      "         [0.5165, 0.4508, 0.5861],\n",
      "         [0.5084, 0.4627, 0.5940],\n",
      "         [0.5494, 0.5128, 0.6385],\n",
      "         [0.5956, 0.5905, 0.6653],\n",
      "         [0.6252, 0.6141, 0.6665]]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1700 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ensure it's in evaluation mode for visualization\n",
    "model_res50.eval()  # This changes the model to evaluation mode\n",
    "\n",
    "# Get the weights of the first convolutional layer\n",
    "weights = model_res50.conv1.weight.data.cpu()\n",
    "\n",
    "# Normalize the weights for better visualization\n",
    "weights = (weights - weights.min()) / (weights.max() - weights.min())\n",
    "print(weights[0])\n",
    "print(weights[0].permute(1, 2, 0))\n",
    "# Plot the first few filters\n",
    "plt.figure(figsize=(20, 17))\n",
    "for i in range(64):  # Let's visualize 64 filters\n",
    "    plt.subplot(8, 8, i + 1)\n",
    "    plt.imshow(weights[i].permute(1, 2, 0))  # Rearrange the dimensions\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING: Object Detection is not yet fully built out. Certain operations packaged into their own functions for Image Classification have not yet been done for Object Detection. The Object Detection training loop is functional, but it currently operates on very large images. More work is needed before this portion of the code base will function properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import FasterRCNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained fasterrcnn_mobilenet_v3_large_fpn model\n",
    "model_fastercnn = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT)\n",
    "\n",
    "# Replace the classifier with a new one for binary classification (background + pedestrian)\n",
    "num_classes = 2  # 1 class (pedestrian) + background\n",
    "# Get the number of input features for the classifier\n",
    "in_features = model_fastercnn.roi_heads.box_predictor.cls_score.in_features\n",
    "# Replace the pre-trained head with a new one (note: this automatically changes the anchor generator to match the backbone)\n",
    "model_fastercnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model_fastercnn = model_fastercnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our Dataset and Dataloader objects for object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Collate function and IoU function. IoU is used in Object Detection in order to determine if a proposed bounding box deliniates the object well enough wrt the ground truth box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generated by ChatGPT 4\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for handling varying sizes of bounding boxes and labels.\n",
    "    \"\"\"\n",
    "    batch = list(filter(lambda x: x is not None, batch))\n",
    "    if not batch:\n",
    "        return torch.tensor([]), {}\n",
    "\n",
    "    images = [item[0] for item in batch]\n",
    "    targets = [item[1] for item in batch]\n",
    "\n",
    "    images = default_collate(images)  # Stack images as they should have the same size\n",
    "    # Do not stack targets as they can have varying sizes\n",
    "    return images, targets\n",
    "\n",
    "#Code below created with ChatGPT 4\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    Parameters:\n",
    "    box1 (list of floats): bounding box in format [x_min, y_min, x_max, y_max].\n",
    "    box2 (list of floats): bounding box in format [x_min, y_min, x_max, y_max].\n",
    "\n",
    "    Returns:\n",
    "    float: IoU of box1 and box2.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "    x_left = max(box1[0], box2[0])\n",
    "    y_top = max(box1[1], box2[1])\n",
    "    x_right = min(box1[2], box2[2])\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "    # Check if there is no overlap\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate area of intersection rectangle\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # Calculate area of both bounding boxes\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    # Calculate combined area\n",
    "    total_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = intersection_area / total_area\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below we create our Dataset and DataLoaders for both our training loop and validation loop. Currently, both training and validation are in the same loop, and it's implementation is not yet sufficient for proper usage. Updates to come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_base_path = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\images\")\n",
    "\n",
    "#Training Dataset and DataLoader\n",
    "train_image_box_lookup_path = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\img_bx_lookup\\train_merged.json\")\n",
    "with open(train_image_box_lookup_path, \"r\") as file:\n",
    "    train_image_box_lookup = json.load(file)\n",
    "dataset_training_detection = Lyft_binary_object_detection_CustomDataset(train_image_box_lookup, images_base_path=images_base_path, transform=None, random_sample=None, positive_imgs_only=True)\n",
    "# Use the custom collate function in the DataLoader\n",
    "batch_size=10\n",
    "dataloader_training_detection = DataLoader(dataset_training_detection, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "print(\"total number of training batches to anticipate: \", len(dataset_training_detection)/batch_size, \"Dataset total length: \", len(dataset_training_detection))\n",
    "\n",
    "\n",
    "#Validation Dataset and DataLoader\n",
    "validation_image_box_lookup_path = os.path.join(user_path_prefix, r\"3d-object-detection-for-autonomous-vehicles\\Train\\img_bx_lookup\\validation_merged.json\")\n",
    "with open(validation_image_box_lookup_path, \"r\") as file:\n",
    "    validation_image_box_lookup = json.load(file)\n",
    "dataset_validation_detection = Lyft_binary_object_detection_CustomDataset(validation_image_box_lookup, images_base_path=images_base_path, transform=None, random_sample=None, positive_imgs_only=True)\n",
    "# Use the custom collate function in the DataLoader\n",
    "batch_size=10\n",
    "dataloader_validation_detection = DataLoader(dataset_validation_detection, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "print(\"total number of validation batches to anticipate: \", len(dataset_validation_detection)/batch_size, \"Dataset total length: \", len(dataset_validation_detection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you find yourself unsure of how to interpret the loop below, while it is incomplete, you can defer to the \"train_resnet50_classification\" function under the Image Classification section. This approach is different, but similar in nature and has clearer code and explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before starting your training loop\n",
    "torch.cuda.empty_cache()  # Clear cache if any\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "iou_threshold = 0.5\n",
    "optimizer = torch.optim.Adam(model_fastercnn.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()  # Start time for the epoch\n",
    "    model_fastercnn.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    total_true_positives = 0\n",
    "    total_false_positives = 0\n",
    "    total_false_negatives = 0\n",
    "    batch_i = 0\n",
    "\n",
    "    for images, targets in dataloader_training_detection:\n",
    "        batch_start_time = time.time()\n",
    "        print(\"On batch: \", batch_i)\n",
    "        batch_i += 1\n",
    "        \n",
    "        images = images.to(device)\n",
    "        targets_on_device = []\n",
    "        for target in targets:\n",
    "            target_on_device = {key: value.to(device) if isinstance(value, torch.Tensor) else value for key, value in target.items()}\n",
    "            targets_on_device.append(target_on_device)\n",
    "\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()  # Clear existing gradients\n",
    "        loss_dict = model_fastercnn(images, targets_on_device)  # Forward pass\n",
    "        losses = sum(loss for loss in loss_dict.values())  # Sum up all losses\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        losses.backward()  # Compute gradients\n",
    "        optimizer.step()  # Update model parameters\n",
    "        running_loss += losses.item()\n",
    "        batch_duration = time.time() - batch_start_time  # Calculate duration for the batch\n",
    "        print(f'Batch Duration: {batch_duration:.2f} seconds')\n",
    "\n",
    "    # Evaluation mode for inference\n",
    "    model_fastercnn.eval()\n",
    "    inference_batch_i = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in dataloader_validation_detection:\n",
    "            inference_batch_start_time = time.time()\n",
    "            print(\"On inference batch: \", inference_batch_i)\n",
    "            inference_batch_i += 1\n",
    "            \n",
    "            images = images.to(device)\n",
    "            predictions = model_fastercnn(images)\n",
    "            filenames = dataloader_validation_detection.dataset.file_names\n",
    "            try:\n",
    "                # Update the dictionary with predictions\n",
    "                for filename, target, prediction in zip(filenames, targets, predictions):\n",
    "                    predicted_boxes = prediction['boxes'].cpu().numpy().tolist()\n",
    "                    predicted_labels = prediction['labels'].cpu().numpy().tolist()\n",
    "                    print(\"predicted boxex: \", predicted_boxes)\n",
    "                    print(\"predicted labels: \", predicted_labels)\n",
    "\n",
    "                    if \"predicted_boxes\" in validation_image_box_lookup.keys():\n",
    "                        validation_image_box_lookup[filename]['predicted_boxes'].extend(predicted_boxes)\n",
    "                    else:\n",
    "                        validation_image_box_lookup[filename]['predicted_boxes'] = predicted_boxes\n",
    "                    if \"predicted_labels\" in validation_image_box_lookup.keys():\n",
    "                        validation_image_box_lookup[filename]['predicted_labels'].extend(predicted_labels)\n",
    "                    else:\n",
    "                        validation_image_box_lookup[filename]['predicted_labels'] = predicted_labels\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "            \n",
    "            #Calculate IoU\n",
    "            for target, prediction in zip(targets, predictions):\n",
    "                ground_truth_boxes = target[\"boxes\"]\n",
    "                predicted_boxes = prediction[\"boxes\"]\n",
    "\n",
    "                if len(predicted_boxes) > 0:\n",
    "                    iou = calculate_iou(predicted_boxes[0], ground_truth_boxes[0])\n",
    "\n",
    "                    if iou >= iou_threshold:\n",
    "                        total_true_positives += 1\n",
    "                    else:\n",
    "                        total_false_positives += 1\n",
    "                else:\n",
    "                    total_false_negatives += 1\n",
    "            \n",
    "            inference_batch_duration = time.time() - inference_batch_start_time  # Calculate duration for the batch\n",
    "            print(f'Inference Batch Duration: {inference_batch_duration:.2f} seconds')\n",
    "\n",
    "    # Calculate metrics after each epoch\n",
    "    precision = total_true_positives / (total_true_positives + total_false_positives) if (total_true_positives + total_false_positives) > 0 else 0\n",
    "    recall = total_true_positives / (total_true_positives + total_false_negatives) if (total_true_positives + total_false_negatives) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    model_fastercnn.train()  # Set back to training mode\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader_training_detection.dataset)\n",
    "    epoch_duration = time.time() - epoch_start_time  # Calculate duration for the epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1_score:.4f}, Duration: {epoch_duration:.2f} seconds\")\n",
    "\n",
    "    #Save after each epoch.\n",
    "    model_fastercnn_dict = model_fastercnn.state_dict()\n",
    "    # torch.save(model_fastercnn_dict, r\"S:\\MADS\\Capstone\\3d-object-detection-for-autonomous-vehicles\\Train\\models\\model_fastercnn_12_2_23_00_00\")\n",
    "\n",
    "    # It is Pytorch convention to save checkpoints of model states as '.pth' which is short of 'Pytorch'. This uses Python pickle module to serialize the data.\n",
    "    # For now, we simply append the time the model was saved to the end of its name to distinguish it. \n",
    "    current_time = time.localtime()\n",
    "    # Format the time in the desired format: \"day_month_year_hour_minute_second\"\n",
    "    time_str = time.strftime(\"%d_%m_%Y_%H_%M_%S\", current_time)\n",
    "\n",
    "    base_name = \"model_res50_batchsize\"\n",
    "    model_checkpoint_name = f\"{base_name}_{time_str}.pth\"\n",
    "    model_outpath = os.path.join(out_results_path, model_checkpoint_name)\n",
    "    torch.save(checkpoint, model_outpath)\n",
    "\n",
    "    #Output our resulting validation data dict with the predictions appended to it. Recall that this is the initial data dict that is read in in our dataset_training_detection.\n",
    "    predictions_filename = r\"validation_merged_w_predictions.json\"\n",
    "    predictions_output_path = os.path.join(validation_image_box_lookup_path, predictions_filename)\n",
    "    with open(predictions_output_path, \"w\") as outfile:\n",
    "        json.dump(validation_image_box_lookup, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
